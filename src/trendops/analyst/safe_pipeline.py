# src/trendops/analyst/safe_pipeline.py
"""
Week 4 Day 4: Self-Correction Loop êµ¬í˜„

Blueprint Week 4 í•µì‹¬: "í”„ë¡œë•ì…˜ ë ˆë²¨ LLM íŒŒì´í”„ë¼ì¸"

êµ¬ì¡°:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Stage 1       â”‚     â”‚   Stage 2       â”‚     â”‚   Stage 3       â”‚
â”‚   Structured    â”‚â”€â”€â”€â”€â–¶â”‚   Guardrail     â”‚â”€â”€â”€â”€â–¶â”‚   Output        â”‚
â”‚   Generation    â”‚     â”‚   Review        â”‚     â”‚   Decision      â”‚
â”‚   (Day 1)       â”‚     â”‚   (Day 3)       â”‚     â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â–¼            â–¼            â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚   PASS   â”‚ â”‚  REVISE  â”‚ â”‚  REJECT  â”‚
              â”‚ (Output) â”‚ â”‚ (Retry)  â”‚ â”‚  (Log)   â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

íŠ¹ì§•:
1. StructuredAnalyzer (Day 1) + ContentGuardrail (Day 3) í†µí•©
2. Self-Correction: Guardrail ì‹¤íŒ¨ ì‹œ ìë™ ìˆ˜ì • í›„ ì¬ì‹œë„
3. ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì œí•œ
4. ìƒì„¸í•œ íŒŒì´í”„ë¼ì¸ ìƒíƒœ ì¶”ì 
5. ë©”íŠ¸ë¦­ìŠ¤ ìˆ˜ì§‘ (ì„±ê³µë¥ , ìˆ˜ì •ë¥ , ê±°ë¶€ìœ¨)

ì‚¬ìš©ë²•:
    async with SafeAnalysisPipeline() as pipeline:
        result = await pipeline.analyze_safely(
            keyword="íŠ¸ëŸ¼í”„ ê´€ì„¸",
            articles=[...],
        )
        
        if result.success:
            print(result.analysis)
        else:
            print(f"Failed: {result.failure_reason}")
"""

from __future__ import annotations

import asyncio
import time
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
from typing import Any, Callable
from uuid import uuid4

from pydantic import BaseModel, Field

# Day 2 ìŠ¤í‚¤ë§ˆ
try:
    from trendops.schemas import (
        GuardrailAction,
        GuardrailResult,
        AnalysisResult,
        AnalysisOutput,
        SentimentRatio,
        PipelineError,
        PipelineStage,
        ErrorCategory,
        ErrorSeverity,
        GenerationMethod,
    )
except ImportError:
    # ë‹¨ë… ì‹¤í–‰ ì‹œ fallback (í…ŒìŠ¤íŠ¸ìš©)
    from schemas import (
        GuardrailAction,
        GuardrailResult,
        AnalysisResult,
        AnalysisOutput,
        SentimentRatio,
        PipelineError,
        PipelineStage,
        ErrorCategory,
        ErrorSeverity,
        GenerationMethod,
    )

# Day 3 Guardrail
try:
    from trendops.analyst.guardrail import ContentGuardrail, GuardrailConfig
except ImportError:
    # ë‹¨ë… ì‹¤í–‰ ì‹œ fallback (í…ŒìŠ¤íŠ¸ìš©)
    from .guardrail import ContentGuardrail, GuardrailConfig


# =============================================================================
# Pipeline Result Schema
# =============================================================================

class PipelineStatus(str, Enum):
    """íŒŒì´í”„ë¼ì¸ ìƒíƒœ"""
    SUCCESS = "success"           # ì •ìƒ ì™„ë£Œ
    REVISED = "revised"           # ìˆ˜ì • í›„ ì™„ë£Œ
    REJECTED = "rejected"         # ê±°ë¶€ë¨
    FAILED = "failed"             # ì‹œìŠ¤í…œ ì—ëŸ¬
    PENDING_REVIEW = "pending_review"  # ì‚¬ëŒ ê²€í†  í•„ìš”


@dataclass
class PipelineMetrics:
    """íŒŒì´í”„ë¼ì¸ ë©”íŠ¸ë¦­ìŠ¤"""
    total_attempts: int = 0
    successful: int = 0
    revised: int = 0
    rejected: int = 0
    failed: int = 0
    pending_review: int = 0
    
    # ì‹œê°„ ë©”íŠ¸ë¦­ìŠ¤
    total_time_seconds: float = 0.0
    avg_time_seconds: float = 0.0
    
    # Guardrail ë©”íŠ¸ë¦­ìŠ¤
    guardrail_pass_rate: float = 0.0
    revision_attempts: int = 0
    
    def record(self, status: PipelineStatus, time_seconds: float):
        """ê²°ê³¼ ê¸°ë¡"""
        self.total_attempts += 1
        self.total_time_seconds += time_seconds
        self.avg_time_seconds = self.total_time_seconds / self.total_attempts
        
        if status == PipelineStatus.SUCCESS:
            self.successful += 1
        elif status == PipelineStatus.REVISED:
            self.revised += 1
        elif status == PipelineStatus.REJECTED:
            self.rejected += 1
        elif status == PipelineStatus.FAILED:
            self.failed += 1
        elif status == PipelineStatus.PENDING_REVIEW:
            self.pending_review += 1
        
        # Pass rate ê³„ì‚° (SUCCESS + REVISED)
        passed = self.successful + self.revised
        if self.total_attempts > 0:
            self.guardrail_pass_rate = passed / self.total_attempts
    
    def to_dict(self) -> dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            "total_attempts": self.total_attempts,
            "successful": self.successful,
            "revised": self.revised,
            "rejected": self.rejected,
            "failed": self.failed,
            "pending_review": self.pending_review,
            "guardrail_pass_rate": round(self.guardrail_pass_rate, 3),
            "avg_time_seconds": round(self.avg_time_seconds, 2),
        }


class SafePipelineResult(BaseModel):
    """
    Self-Correction Pipeline ê²°ê³¼
    
    ë¶„ì„ ê²°ê³¼ + Guardrail ê²°ê³¼ + íŒŒì´í”„ë¼ì¸ ë©”íƒ€ë°ì´í„°
    """
    # ì‹ë³„ì
    pipeline_id: str = Field(default_factory=lambda: f"pipe-{uuid4().hex[:8]}")
    keyword: str = Field(..., description="ë¶„ì„ í‚¤ì›Œë“œ")
    
    # ê²°ê³¼
    success: bool = Field(..., description="ì„±ê³µ ì—¬ë¶€")
    status: PipelineStatus = Field(..., description="íŒŒì´í”„ë¼ì¸ ìƒíƒœ")
    
    # ë¶„ì„ ê²°ê³¼ (ì„±ê³µ ì‹œ)
    analysis: AnalysisResult | None = Field(default=None, description="ë¶„ì„ ê²°ê³¼")
    
    # Guardrail ê²°ê³¼
    guardrail_result: GuardrailResult | None = Field(default=None, description="Guardrail ê²€ì‚¬ ê²°ê³¼")
    
    # ìˆ˜ì • ì´ë ¥
    revision_count: int = Field(default=0, description="ìˆ˜ì • ì‹œë„ íšŸìˆ˜")
    original_content: str | None = Field(default=None, description="ì›ë³¸ ì½˜í…ì¸  (ìˆ˜ì •ëœ ê²½ìš°)")
    
    # ì‹¤íŒ¨ ì •ë³´
    failure_reason: str | None = Field(default=None, description="ì‹¤íŒ¨ ì‚¬ìœ ")
    errors: list[dict] = Field(default_factory=list, description="ë°œìƒí•œ ì—ëŸ¬ ëª©ë¡")
    
    # ë©”íƒ€ë°ì´í„°
    total_time_seconds: float = Field(default=0.0, description="ì´ ì†Œìš” ì‹œê°„")
    stage_times: dict[str, float] = Field(default_factory=dict, description="ë‹¨ê³„ë³„ ì†Œìš” ì‹œê°„")
    created_at: datetime = Field(default_factory=datetime.now, description="ìƒì„± ì‹œê°„")
    
    @property
    def is_usable(self) -> bool:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ê²°ê³¼ì¸ì§€ (SUCCESS ë˜ëŠ” REVISED)"""
        return self.status in (PipelineStatus.SUCCESS, PipelineStatus.REVISED)
    
    @property
    def needs_review(self) -> bool:
        """ì‚¬ëŒ ê²€í† ê°€ í•„ìš”í•œì§€"""
        return self.status == PipelineStatus.PENDING_REVIEW
    
    def get_final_summary(self) -> str | None:
        """ìµœì¢… ìš”ì•½ ë°˜í™˜ (ìˆ˜ì •ëœ ë²„ì „ ìš°ì„ )"""
        if self.guardrail_result and self.guardrail_result.revised_content:
            return self.guardrail_result.revised_content
        if self.analysis:
            return self.analysis.analysis.summary
        return None


# =============================================================================
# Mock Analyzer (í…ŒìŠ¤íŠ¸ìš©)
# =============================================================================

class MockStructuredAnalyzer:
    """í…ŒìŠ¤íŠ¸ìš© Mock Analyzer"""
    
    MOCK_ANALYSIS = {
        "main_cause": "í•´ë‹¹ í‚¤ì›Œë“œì— ëŒ€í•œ ëŒ€ì¤‘ì  ê´€ì‹¬ì´ ê¸‰ì¦í•˜ì—¬ í™”ì œê°€ ë˜ê³  ìˆìŠµë‹ˆë‹¤",
        "sentiment_ratio": {
            "positive": 0.25,
            "negative": 0.45,
            "neutral": 0.30
        },
        "key_opinions": [
            "êµ­ë‚´ ê²½ì œì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì— ëŒ€í•œ ìš°ë ¤ê°€ í™•ì‚°ë˜ê³  ìˆìŠµë‹ˆë‹¤",
            "ì „ë¬¸ê°€ë“¤ì€ ì¥ê¸°ì  ê´€ì ì—ì„œ ë¶„ì„ì´ í•„ìš”í•˜ë‹¤ê³  ì§€ì í•©ë‹ˆë‹¤",
            "ì†Œë¹„ìë“¤ì˜ ë°˜ì‘ì€ ë‹¤ì–‘í•˜ê²Œ ë‚˜íƒ€ë‚˜ê³  ìˆìŠµë‹ˆë‹¤",
            "ê´€ë ¨ ì—…ê³„ì—ì„œëŠ” ëŒ€ì‘ì±… ë§ˆë ¨ì— ë‚˜ì„œê³  ìˆìŠµë‹ˆë‹¤"
        ],
        "summary": "í•´ë‹¹ ì´ìŠˆê°€ í™”ì œê°€ ë˜ë©´ì„œ ë‹¤ì–‘í•œ ì˜ê²¬ì´ ì œì‹œë˜ê³  ìˆìŠµë‹ˆë‹¤.\nê²½ì œì  ì˜í–¥ì— ëŒ€í•œ ë¶„ì„ê³¼ í•¨ê»˜ ì „ë¬¸ê°€ë“¤ì˜ ê²¬í•´ê°€ ì£¼ëª©ë°›ê³  ìˆìŠµë‹ˆë‹¤.\ní–¥í›„ ì¶”ì´ë¥¼ ì§€ì¼œë´ì•¼ í•  ê²ƒìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤."
    }
    
    def __init__(self, model_name: str = "mock-model"):
        self.model_name = model_name
    
    async def analyze(
        self,
        keyword: str,
        articles: list[dict[str, Any]],
    ) -> AnalysisResult:
        """Mock ë¶„ì„ ìˆ˜í–‰"""
        await asyncio.sleep(0.3)  # ì‹œë®¬ë ˆì´ì…˜
        
        analysis_output = AnalysisOutput.model_validate(self.MOCK_ANALYSIS)
        
        return AnalysisResult(
            keyword=keyword,
            analysis=analysis_output,
            source_count=len(articles),
            model_version=self.model_name,
            inference_time_seconds=0.3,
            generation_method=GenerationMethod.MOCK,
        )
    
    async def close(self):
        pass
    
    async def __aenter__(self):
        return self
    
    async def __aexit__(self, *args):
        await self.close()


# =============================================================================
# Safe Analysis Pipeline
# =============================================================================

class SafeAnalysisPipeline:
    """
    Self-Correctionì´ ì ìš©ëœ ì•ˆì „í•œ ë¶„ì„ íŒŒì´í”„ë¼ì¸
    
    Blueprint Week 4: 2-Stage Guardrail + Self-Correction
    
    Flow:
    1. Structured Generation (StructuredAnalyzer)
    2. Guardrail Review (ContentGuardrail)
    3. Actionì— ë”°ë¥¸ ì²˜ë¦¬:
       - PASS: ê²°ê³¼ ë°˜í™˜
       - REVISE: ìˆ˜ì • í›„ ì¬ê²€ì¦
       - REVIEW: ì‚¬ëŒ ê²€í†  ëŒ€ê¸°ì—´
       - REJECT: ê±°ë¶€ ë° ë¡œê¹…
    
    Usage:
        async with SafeAnalysisPipeline() as pipeline:
            result = await pipeline.analyze_safely(
                keyword="íŠ¸ëŸ¼í”„ ê´€ì„¸",
                articles=[{"title": "...", "summary": "..."}],
            )
            
            if result.success:
                print(result.analysis.analysis.summary)
            elif result.needs_review:
                print("ì‚¬ëŒ ê²€í†  í•„ìš”:", result.guardrail_result.review_reason)
            else:
                print("ê±°ë¶€ë¨:", result.failure_reason)
    """
    
    def __init__(
        self,
        # Analyzer ì„¤ì •
        model_name: str = "qwen2.5:7b-instruct",
        base_url: str = "http://localhost:11434",
        use_outlines: bool = True,
        
        # Guardrail ì„¤ì •
        guardrail_config: GuardrailConfig | None = None,
        strict_mode: bool = False,
        
        # íŒŒì´í”„ë¼ì¸ ì„¤ì •
        max_revisions: int = 2,
        enable_auto_revision: bool = True,
        
        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ
        use_mock: bool = False,
    ):
        """
        Args:
            model_name: Ollama ëª¨ë¸ ì´ë¦„
            base_url: Ollama ì„œë²„ URL
            use_outlines: Outlines ì‚¬ìš© ì—¬ë¶€
            guardrail_config: Guardrail ì„¤ì •
            strict_mode: ì—„ê²© ëª¨ë“œ
            max_revisions: ìµœëŒ€ ìˆ˜ì • ì‹œë„ íšŸìˆ˜
            enable_auto_revision: ìë™ ìˆ˜ì • í™œì„±í™”
            use_mock: Mock ëª¨ë“œ (í…ŒìŠ¤íŠ¸ìš©)
        """
        self.model_name = model_name
        self.base_url = base_url
        self.use_outlines = use_outlines
        self.strict_mode = strict_mode
        self.max_revisions = max_revisions
        self.enable_auto_revision = enable_auto_revision
        self.use_mock = use_mock
        
        # Guardrail ì„¤ì •
        self.guardrail_config = guardrail_config or GuardrailConfig(
            strict_mode=strict_mode,
            llm_model=model_name,
            llm_base_url=base_url,
        )
        
        # ì»´í¬ë„ŒíŠ¸ ì´ˆê¸°í™” (lazy)
        self._analyzer = None
        self._guardrail = None
        
        # ë©”íŠ¸ë¦­ìŠ¤
        self.metrics = PipelineMetrics()
        
        # ì½œë°±
        self._on_revision: Callable[[str, str], None] | None = None
        self._on_rejection: Callable[[str, str], None] | None = None
    
    def _init_components(self):
        """ì»´í¬ë„ŒíŠ¸ lazy ì´ˆê¸°í™”"""
        if self._analyzer is None:
            if self.use_mock:
                self._analyzer = MockStructuredAnalyzer(model_name=self.model_name)
            else:
                # ì‹¤ì œ StructuredAnalyzer import ì‹œë„
                try:
                    from trendops.analyst.structured_analyzer import StructuredAnalyzer
                    self._analyzer = StructuredAnalyzer(
                        model_name=self.model_name,
                        base_url=self.base_url,
                        use_outlines=self.use_outlines,
                    )
                except ImportError:
                    try:
                        # ë‹¨ë… ì‹¤í–‰ ì‹œ fallback (í…ŒìŠ¤íŠ¸ìš©)
                        from .structured_analyzer import StructuredAnalyzer
                        self._analyzer = StructuredAnalyzer(
                            model_name=self.model_name,
                            base_url=self.base_url,
                            use_outlines=self.use_outlines,
                        )
                    except ImportError:
                        print("[WARNING] StructuredAnalyzer not found, using Mock")
                        self._analyzer = MockStructuredAnalyzer(model_name=self.model_name)
        
        if self._guardrail is None:
            self._guardrail = ContentGuardrail(
                config=self.guardrail_config,
                use_mock=self.use_mock,
            )
    
    def on_revision(self, callback: Callable[[str, str], None]):
        """ìˆ˜ì • ë°œìƒ ì‹œ ì½œë°± ë“±ë¡"""
        self._on_revision = callback
    
    def on_rejection(self, callback: Callable[[str, str], None]):
        """ê±°ë¶€ ë°œìƒ ì‹œ ì½œë°± ë“±ë¡"""
        self._on_rejection = callback
    
    async def analyze_safely(
        self,
        keyword: str,
        articles: list[dict[str, Any]],
    ) -> SafePipelineResult:
        """
        ì•ˆì „í•œ ë¶„ì„ ìˆ˜í–‰ (Self-Correction ì ìš©)
        
        Args:
            keyword: ë¶„ì„ í‚¤ì›Œë“œ
            articles: ë‰´ìŠ¤ ê¸°ì‚¬ ëª©ë¡
        
        Returns:
            SafePipelineResult: íŒŒì´í”„ë¼ì¸ ê²°ê³¼
        """
        self._init_components()
        
        start_time = time.time()
        stage_times: dict[str, float] = {}
        errors: list[dict] = []
        
        pipeline_id = f"pipe-{uuid4().hex[:8]}"
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Stage 1: Structured Generation
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        stage1_start = time.time()
        
        try:
            analysis_result = await self._analyzer.analyze(keyword, articles)
            stage_times["generation"] = round(time.time() - stage1_start, 2)
        except Exception as e:
            stage_times["generation"] = round(time.time() - stage1_start, 2)
            errors.append({
                "stage": "generation",
                "error": str(e),
                "recoverable": False,
            })
            
            total_time = time.time() - start_time
            self.metrics.record(PipelineStatus.FAILED, total_time)
            
            return SafePipelineResult(
                pipeline_id=pipeline_id,
                keyword=keyword,
                success=False,
                status=PipelineStatus.FAILED,
                failure_reason=f"ë¶„ì„ ìƒì„± ì‹¤íŒ¨: {e}",
                errors=errors,
                total_time_seconds=round(total_time, 2),
                stage_times=stage_times,
            )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Stage 2: Guardrail Review (+ Self-Correction Loop)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        content_to_check = analysis_result.analysis.summary
        original_content = content_to_check
        revision_count = 0
        guardrail_result: GuardrailResult | None = None
        
        for attempt in range(self.max_revisions + 1):
            stage2_start = time.time()
            
            try:
                guardrail_result = await self._guardrail.check(
                    content=content_to_check,
                    keyword=keyword,
                    strict_mode=self.strict_mode,
                )
                stage_times[f"guardrail_{attempt}"] = round(time.time() - stage2_start, 2)
            except Exception as e:
                stage_times[f"guardrail_{attempt}"] = round(time.time() - stage2_start, 2)
                errors.append({
                    "stage": f"guardrail_{attempt}",
                    "error": str(e),
                    "recoverable": True,
                })
                # Guardrail ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (ê¸°ë³¸ PASS ì²˜ë¦¬)
                guardrail_result = GuardrailResult(
                    content_id=f"fallback-{uuid4().hex[:8]}",
                    action=GuardrailAction.PASS,
                    is_safe=True,
                    confidence=0.5,
                    issues=[],
                    original_content=content_to_check,
                )
                break
            
            # Actionì— ë”°ë¥¸ ì²˜ë¦¬
            if guardrail_result.action == GuardrailAction.PASS:
                # í†µê³¼ - ë£¨í”„ ì¢…ë£Œ
                break
            
            elif guardrail_result.action == GuardrailAction.REVISE:
                # ìˆ˜ì • ì‹œë„
                if not self.enable_auto_revision or attempt >= self.max_revisions:
                    break
                
                if guardrail_result.revised_content:
                    # ìˆ˜ì •ëœ ì½˜í…ì¸ ë¡œ ì¬ê²€ì¦
                    content_to_check = guardrail_result.revised_content
                    revision_count += 1
                    self.metrics.revision_attempts += 1
                    
                    # ì½œë°± í˜¸ì¶œ
                    if self._on_revision:
                        self._on_revision(original_content, content_to_check)
                else:
                    # ìë™ ìˆ˜ì • ì‹¤íŒ¨ - ë£¨í”„ ì¢…ë£Œ
                    break
            
            elif guardrail_result.action == GuardrailAction.REVIEW:
                # ì‚¬ëŒ ê²€í†  í•„ìš” - ë£¨í”„ ì¢…ë£Œ
                break
            
            elif guardrail_result.action == GuardrailAction.REJECT:
                # ê±°ë¶€ - ë£¨í”„ ì¢…ë£Œ
                if self._on_rejection:
                    self._on_rejection(keyword, guardrail_result.issue_summary)
                break
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Stage 3: Result Decision
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        total_time = time.time() - start_time
        
        # ìµœì¢… ìƒíƒœ ê²°ì •
        if guardrail_result.action == GuardrailAction.PASS:
            if revision_count > 0:
                status = PipelineStatus.REVISED
            else:
                status = PipelineStatus.SUCCESS
            success = True
            failure_reason = None
            
        elif guardrail_result.action == GuardrailAction.REVISE:
            # ìˆ˜ì • ì‹œë„í–ˆì§€ë§Œ ìµœëŒ€ íšŸìˆ˜ ë„ë‹¬
            status = PipelineStatus.REVISED
            success = True
            failure_reason = None
            
        elif guardrail_result.action == GuardrailAction.REVIEW:
            status = PipelineStatus.PENDING_REVIEW
            success = False
            failure_reason = guardrail_result.review_reason or "ì‚¬ëŒ ê²€í†  í•„ìš”"
            
        else:  # REJECT
            status = PipelineStatus.REJECTED
            success = False
            failure_reason = f"Guardrail ê±°ë¶€: {guardrail_result.issue_summary}"
        
        # ë©”íŠ¸ë¦­ìŠ¤ ê¸°ë¡
        self.metrics.record(status, total_time)
        
        # ê²°ê³¼ ìƒì„±
        return SafePipelineResult(
            pipeline_id=pipeline_id,
            keyword=keyword,
            success=success,
            status=status,
            analysis=analysis_result if success else None,
            guardrail_result=guardrail_result,
            revision_count=revision_count,
            original_content=original_content if revision_count > 0 else None,
            failure_reason=failure_reason,
            errors=errors,
            total_time_seconds=round(total_time, 2),
            stage_times=stage_times,
        )
    
    async def analyze_batch(
        self,
        items: list[tuple[str, list[dict[str, Any]]]],
        concurrency: int = 3,
    ) -> list[SafePipelineResult]:
        """
        ë°°ì¹˜ ë¶„ì„ ìˆ˜í–‰
        
        Args:
            items: [(keyword, articles), ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
            concurrency: ë™ì‹œ ì²˜ë¦¬ ìˆ˜
        
        Returns:
            SafePipelineResult ë¦¬ìŠ¤íŠ¸
        """
        semaphore = asyncio.Semaphore(concurrency)
        
        async def analyze_with_limit(keyword: str, articles: list[dict]):
            async with semaphore:
                return await self.analyze_safely(keyword, articles)
        
        tasks = [analyze_with_limit(kw, arts) for kw, arts in items]
        return await asyncio.gather(*tasks)
    
    def get_metrics(self) -> dict[str, Any]:
        """ë©”íŠ¸ë¦­ìŠ¤ ë°˜í™˜"""
        return self.metrics.to_dict()
    
    def reset_metrics(self):
        """ë©”íŠ¸ë¦­ìŠ¤ ì´ˆê¸°í™”"""
        self.metrics = PipelineMetrics()
    
    async def close(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        if self._analyzer and hasattr(self._analyzer, 'close'):
            await self._analyzer.close()
    
    async def __aenter__(self) -> "SafeAnalysisPipeline":
        return self
    
    async def __aexit__(self, *args):
        await self.close()


# =============================================================================
# Convenience Functions
# =============================================================================

async def analyze_keyword_safely(
    keyword: str,
    articles: list[dict[str, Any]],
    use_mock: bool = False,
) -> SafePipelineResult:
    """
    ë‹¨ì¼ í‚¤ì›Œë“œ ì•ˆì „ ë¶„ì„ í¸ì˜ í•¨ìˆ˜
    
    Usage:
        result = await analyze_keyword_safely(
            keyword="íŠ¸ëŸ¼í”„ ê´€ì„¸",
            articles=[{"title": "...", "summary": "..."}],
        )
    """
    async with SafeAnalysisPipeline(use_mock=use_mock) as pipeline:
        return await pipeline.analyze_safely(keyword, articles)


# =============================================================================
# CLI Test
# =============================================================================

if __name__ == "__main__":
    async def main():
        """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        print("\n" + "=" * 70)
        print("  Week 4 Day 4: Safe Analysis Pipeline Test")
        print("  Self-Correction Loop Demo")
        print("=" * 70)
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_articles = [
            {
                "title": "íŠ¸ëŸ¼í”„, ì¤‘êµ­ì‚° ì œí’ˆ 25% ê´€ì„¸ ë¶€ê³¼ ë°œí‘œ",
                "summary": "ë¯¸êµ­ ëŒ€í†µë ¹ì´ ë¬´ì—­ ì „ìŸ ê²©í™” ì†ì—ì„œ ìƒˆë¡œìš´ ê´€ì„¸ ì •ì±…ì„ ë°œí‘œí–ˆë‹¤.",
                "source": "ê²½ì œì¼ë³´",
            },
            {
                "title": "êµ­ë‚´ ìˆ˜ì¶œê¸°ì—…ë“¤ 'ë¹„ìƒ'â€¦ë°˜ë„ì²´Â·ë°°í„°ë¦¬ ì—…ì¢… íƒ€ê²© ìš°ë ¤",
                "summary": "ë¯¸êµ­ì˜ ê´€ì„¸ ì •ì±… ë°œí‘œ ì´í›„ êµ­ë‚´ ìˆ˜ì¶œ ê¸°ì—…ë“¤ì´ ë¹„ìƒ ëŒ€ì‘ì— ë‚˜ì„°ë‹¤.",
                "source": "ì‚°ì—…ë‰´ìŠ¤",
            },
            {
                "title": "ì „ë¬¸ê°€ ë¶„ì„: êµ­ë‚´ GDP ì˜í–¥ ì „ë§",
                "summary": "ê²½ì œ ì „ë¬¸ê°€ë“¤ì€ ì¥ê¸°í™”ë  ê²½ìš° êµ­ë‚´ ê²½ì œì— ìƒë‹¹í•œ ì˜í–¥ì´ ìˆì„ ê²ƒìœ¼ë¡œ ë¶„ì„í–ˆë‹¤.",
                "source": "ê²½ì œì—°êµ¬ì†Œ",
            },
        ]
        
        # Mock ëª¨ë“œë¡œ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸
        async with SafeAnalysisPipeline(use_mock=True) as pipeline:
            
            # ì½œë°± ë“±ë¡
            def on_revision(original: str, revised: str):
                print(f"\nğŸ“ ìˆ˜ì • ë°œìƒ!")
                print(f"   ì›ë³¸: {original[:50]}...")
                print(f"   ìˆ˜ì •: {revised[:50]}...")
            
            def on_rejection(keyword: str, reason: str):
                print(f"\nğŸš« ê±°ë¶€ë¨: {keyword}")
                print(f"   ì‚¬ìœ : {reason}")
            
            pipeline.on_revision(on_revision)
            pipeline.on_rejection(on_rejection)
            
            # í…ŒìŠ¤íŠ¸ 1: ì •ìƒ ë¶„ì„
            print("\n" + "â”€" * 60)
            print("Test 1: Normal Analysis")
            print("â”€" * 60)
            
            result = await pipeline.analyze_safely(
                keyword="íŠ¸ëŸ¼í”„ ê´€ì„¸",
                articles=test_articles,
            )
            
            print(f"\nâœ… Pipeline ID: {result.pipeline_id}")
            print(f"   Status: {result.status.value}")
            print(f"   Success: {result.success}")
            print(f"   Time: {result.total_time_seconds:.2f}s")
            print(f"   Stage Times: {result.stage_times}")
            
            if result.success and result.analysis:
                print(f"\nğŸ“Š Analysis Result:")
                print(f"   Keyword: {result.analysis.keyword}")
                print(f"   Main Cause: {result.analysis.analysis.main_cause[:60]}...")
                print(f"   Sentiment: P{result.analysis.analysis.sentiment_ratio.positive:.0%} "
                      f"N{result.analysis.analysis.sentiment_ratio.negative:.0%} "
                      f"U{result.analysis.analysis.sentiment_ratio.neutral:.0%}")
            
            if result.guardrail_result:
                print(f"\nğŸ›¡ï¸ Guardrail Result:")
                print(f"   Action: {result.guardrail_result.action.value}")
                print(f"   Safe: {result.guardrail_result.is_safe}")
                print(f"   Confidence: {result.guardrail_result.confidence:.2f}")
                print(f"   Issues: {len(result.guardrail_result.issues)}")
            
            # í…ŒìŠ¤íŠ¸ 2: ë°°ì¹˜ ë¶„ì„
            print("\n" + "â”€" * 60)
            print("Test 2: Batch Analysis")
            print("â”€" * 60)
            
            batch_items = [
                ("AI ê¸°ìˆ ", test_articles[:2]),
                ("ê²½ì œ ì „ë§", test_articles[1:]),
                ("ë°˜ë„ì²´ ì‹œì¥", test_articles),
            ]
            
            batch_results = await pipeline.analyze_batch(batch_items, concurrency=2)
            
            print(f"\nğŸ“¦ Batch Results: {len(batch_results)} items")
            for r in batch_results:
                status_icon = "âœ…" if r.success else "âŒ"
                print(f"   {status_icon} {r.keyword}: {r.status.value} ({r.total_time_seconds:.2f}s)")
            
            # ë©”íŠ¸ë¦­ìŠ¤ ì¶œë ¥
            print("\n" + "â”€" * 60)
            print("Pipeline Metrics")
            print("â”€" * 60)
            
            metrics = pipeline.get_metrics()
            print(f"\nğŸ“ˆ Metrics:")
            for key, value in metrics.items():
                print(f"   {key}: {value}")
        
        print("\n" + "=" * 70)
        print("  Test Complete!")
        print("=" * 70)
    
    asyncio.run(main())