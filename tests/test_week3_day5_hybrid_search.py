# tests/test_week3_day5_hybrid_search.py
"""
Week 3 Day 5: Hybrid Search í†µí•© í…ŒìŠ¤íŠ¸

í…ŒìŠ¤íŠ¸ ë²”ìœ„:
1. VectorStore (ChromaDB) ê¸°ë³¸ ë™ì‘
2. BM25Index ê¸°ë³¸ ë™ì‘  
3. HybridSearch RRF ìœµí•©
4. A/B í…ŒìŠ¤íŠ¸ ë©”íŠ¸ë¦­
5. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

ì‹¤í–‰ ë°©ë²•:
    python test_week3_day5_hybrid_search.py
"""
from __future__ import annotations

import asyncio
import sys
import time
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ChromaDB ê²½ë¡œ ë“±)
import os
os.environ["CHROMADB_PATH"] = str(project_root / "test_data" / "chromadb")


def print_header(title: str) -> None:
    """ì„¹ì…˜ í—¤ë” ì¶œë ¥"""
    print("\n" + "=" * 70)
    print(f"  {title}")
    print("=" * 70)


def print_subheader(title: str) -> None:
    """ì„œë¸Œ ì„¹ì…˜ í—¤ë” ì¶œë ¥"""
    print(f"\n--- {title} ---")


async def test_vector_store() -> bool:
    """VectorStore í…ŒìŠ¤íŠ¸"""
    print_header("1. VectorStore (ChromaDB) Test")
    
    try:
        from trendops.store.vector_store import VectorStore, get_vector_store, reset_vector_store
        import numpy as np
        
        # ì´ˆê¸°í™”
        reset_vector_store()
        store = get_vector_store()
        
        print_subheader("1.1 Basic Operations")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_keyword = "__test_vs__"
        test_docs = [
            "íŠ¸ëŸ¼í”„ê°€ ì¤‘êµ­ì— ê´€ì„¸ë¥¼ ë¶€ê³¼í–ˆë‹¤.",
            "ë¯¸êµ­ì˜ ë¬´ì—­ ì •ì±…ì´ ë³€ê²½ë˜ì—ˆë‹¤.",
            "ì‚¼ì„±ì „ì ì£¼ê°€ê°€ ìƒìŠ¹í–ˆë‹¤.",
        ]
        
        # ê°€ì§œ ì„ë² ë”© (ì‹¤ì œë¡œëŠ” EmbeddingService ì‚¬ìš©)
        dim = 1024
        embeddings = [np.random.randn(dim).tolist() for _ in test_docs]
        metadatas = [{"keyword": test_keyword, "title": f"Doc {i}"} for i in range(len(test_docs))]
        
        # ì¶”ê°€
        result = store.add_documents(
            contents=test_docs,
            embeddings=embeddings,
            metadatas=metadatas,
        )
        print(f"    âœ“ Added {result.added} documents")
        assert result.added == 3, f"Expected 3, got {result.added}"
        
        # ì¤‘ë³µ ì¶”ê°€ í…ŒìŠ¤íŠ¸
        result2 = store.add_documents(
            contents=test_docs,
            embeddings=embeddings,
            metadatas=metadatas,
        )
        print(f"    âœ“ Duplicate add: added={result2.added}, skipped={result2.skipped}")
        assert result2.skipped == 3, f"Expected 3 skipped, got {result2.skipped}"
        
        print_subheader("1.2 Search Operations")
        
        # ê²€ìƒ‰
        query_emb = np.random.randn(dim).tolist()
        results = store.search(query_emb, top_k=3)
        print(f"    âœ“ Search returned {len(results)} results")
        assert len(results) <= 3
        
        # í‚¤ì›Œë“œ í•„í„° ê²€ìƒ‰
        results = store.search_by_keyword(query_emb, test_keyword, top_k=3)
        print(f"    âœ“ Keyword search returned {len(results)} results")
        
        print_subheader("1.3 Stats and Cleanup")
        
        # í†µê³„
        stats = store.get_stats()
        print(f"    âœ“ Collection: {stats.name}, Documents: {stats.count}")
        
        # ì •ë¦¬
        deleted = store.delete_by_keyword(test_keyword)
        print(f"    âœ“ Deleted {deleted} test documents")
        
        print("\nâœ… VectorStore tests passed!")
        return True
        
    except Exception as e:
        print(f"\nâŒ VectorStore test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_bm25_index() -> bool:
    """BM25Index í…ŒìŠ¤íŠ¸"""
    print_header("2. BM25Index Test")
    
    try:
        from trendops.search.bm25_index import BM25Index, get_bm25_index, reset_bm25_index
        
        # ì´ˆê¸°í™”
        reset_bm25_index()
        index = get_bm25_index()
        
        print_subheader("2.1 Tokenization")
        
        # í† í¬ë‚˜ì´ì € í…ŒìŠ¤íŠ¸
        tokenizer = index.tokenizer
        sample = "íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ì˜ ê´€ì„¸ ì •ì±…ì´ ë°œí‘œë˜ì—ˆë‹¤."
        tokens = tokenizer.tokenize(sample)
        print(f"    Input: {sample}")
        print(f"    Tokens: {tokens}")
        assert len(tokens) > 0, "Tokenization failed"
        
        print_subheader("2.2 Document Indexing")
        
        # í…ŒìŠ¤íŠ¸ ë¬¸ì„œ
        test_keyword = "__test_bm25__"
        test_docs = [
            ("doc1", "íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ì´ ì¤‘êµ­ì‚° ì œí’ˆì— 25% ê´€ì„¸ë¥¼ ë¶€ê³¼í•œë‹¤ê³  ë°œí‘œí–ˆë‹¤."),
            ("doc2", "ë¯¸êµ­ì˜ ê´€ì„¸ ì •ì±…ì´ ì„¸ê³„ ê²½ì œì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤."),
            ("doc3", "ì‚¼ì„±ì „ì ì£¼ê°€ê°€ ê¸‰ë“±í–ˆë‹¤. ë°˜ë„ì²´ ìˆ˜ìš” ì¦ê°€ ì˜í–¥."),
            ("doc4", "ë¹„íŠ¸ì½”ì¸ ê°€ê²©ì´ ì‹ ê³ ê°€ë¥¼ ê²½ì‹ í–ˆë‹¤."),
            ("doc5", "íŠ¸ëŸ¼í”„ í–‰ì •ë¶€ì˜ ë¬´ì—­ ì •ì±…ì— ëŒ€í•œ ìš°ë ¤ê°€ ì»¤ì§€ê³  ìˆë‹¤."),
        ]
        
        # ì¶”ê°€
        added = index.add_documents(
            doc_ids=[d[0] for d in test_docs],
            documents=[d[1] for d in test_docs],
            metadatas=[{"keyword": test_keyword} for _ in test_docs],
        )
        print(f"    âœ“ Added {added} documents")
        assert added == 5, f"Expected 5, got {added}"
        
        print_subheader("2.3 Search Operations")
        
        # ê²€ìƒ‰
        query = "íŠ¸ëŸ¼í”„ ê´€ì„¸ ì •ì±…"
        results = index.search(query, top_k=3)
        print(f"    Query: '{query}'")
        print(f"    Results ({len(results)}):")
        for r in results:
            print(f"      [{r.rank}] score={r.score:.3f}: {r.document[:40]}...")
        
        assert len(results) > 0, "Search returned no results"
        
        # ìƒìœ„ ê²°ê³¼ê°€ ê´€ì„¸ ê´€ë ¨ì¸ì§€ í™•ì¸
        top_doc = results[0].document
        assert "ê´€ì„¸" in top_doc or "íŠ¸ëŸ¼í”„" in top_doc, "Top result should be about ê´€ì„¸/íŠ¸ëŸ¼í”„"
        
        print_subheader("2.4 Stats and Cleanup")
        
        # í†µê³„
        stats = index.get_stats()
        print(f"    âœ“ Documents: {stats.total_documents}")
        print(f"    âœ“ Vocabulary: {stats.vocabulary_size}")
        print(f"    âœ“ Avg length: {stats.avg_doc_length:.1f}")
        
        # ì •ë¦¬
        cleared = index.clear()
        print(f"    âœ“ Cleared {cleared} documents")
        
        print("\nâœ… BM25Index tests passed!")
        return True
        
    except Exception as e:
        print(f"\nâŒ BM25Index test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_hybrid_search() -> bool:
    """HybridSearch í…ŒìŠ¤íŠ¸"""
    print_header("3. Hybrid Search (RRF Fusion) Test")
    
    try:
        from trendops.search.hybrid_search import (
            HybridSearch, 
            get_hybrid_search, 
            reset_hybrid_search,
            SearchMode,
        )
        from trendops.store.vector_store import get_vector_store, reset_vector_store
        from trendops.search.bm25_index import get_bm25_index, reset_bm25_index
        import numpy as np
        
        # ëª¨ë“  ì¸ìŠ¤í„´ìŠ¤ ì´ˆê¸°í™”
        reset_hybrid_search()
        reset_vector_store()
        reset_bm25_index()
        
        print_subheader("3.1 Setup Test Data")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°
        test_keyword = "__test_hybrid__"
        test_docs = [
            ("íŠ¸ëŸ¼í”„ ëŒ€í†µë ¹ì´ ì¤‘êµ­ì‚° ì œí’ˆì— 25% ê´€ì„¸ë¥¼ ë¶€ê³¼í•œë‹¤ê³  ë°œí‘œí–ˆë‹¤.", "ê´€ì„¸ ë°œí‘œ"),
            ("ë¯¸êµ­ì˜ ê´€ì„¸ ì •ì±…ì´ ì„¸ê³„ ê²½ì œì— ì˜í–¥ì„ ë¯¸ì¹œë‹¤.", "ê²½ì œ ì˜í–¥"),
            ("ì‚¼ì„±ì „ì ì£¼ê°€ê°€ ê¸‰ë“±í–ˆë‹¤. ë°˜ë„ì²´ ìˆ˜ìš” ì¦ê°€ ì˜í–¥.", "ì‚¼ì„± ì£¼ê°€"),
            ("ë¹„íŠ¸ì½”ì¸ ê°€ê²©ì´ ì‹ ê³ ê°€ë¥¼ ê²½ì‹ í–ˆë‹¤.", "ë¹„íŠ¸ì½”ì¸"),
            ("íŠ¸ëŸ¼í”„ í–‰ì •ë¶€ì˜ ë¬´ì—­ ì •ì±…ì— ëŒ€í•œ ìš°ë ¤ê°€ ì»¤ì§€ê³  ìˆë‹¤.", "ë¬´ì—­ ì •ì±…"),
        ]
        
        # VectorStoreì— ì¶”ê°€ (ê°€ì§œ ì„ë² ë”© ì‚¬ìš©)
        vector_store = get_vector_store()
        dim = 1024
        
        contents = [d[0] for d in test_docs]
        embeddings = [np.random.randn(dim).tolist() for _ in test_docs]
        metadatas = [{"keyword": test_keyword, "title": d[1]} for d in test_docs]
        
        # ë¬¸ì„œ ID ìƒì„± (BM25ì™€ ì¼ì¹˜ì‹œí‚¤ê¸° ìœ„í•´)
        from trendops.store.vector_store import VectorStore
        doc_ids = [VectorStore._generate_doc_id(c, m) for c, m in zip(contents, metadatas)]
        
        vector_store.add_documents(
            contents=contents,
            embeddings=embeddings,
            metadatas=metadatas,
            ids=doc_ids,
        )
        print(f"    âœ“ Added {len(test_docs)} documents to VectorStore")
        
        # BM25ì— ì¶”ê°€ (ë™ì¼ ID ì‚¬ìš©)
        bm25_index = get_bm25_index()
        bm25_index.add_documents(
            doc_ids=doc_ids,
            documents=contents,
            metadatas=metadatas,
        )
        print(f"    âœ“ Added {len(test_docs)} documents to BM25Index")
        
        print_subheader("3.2 Hybrid Search")
        
        # HybridSearch ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        search = get_hybrid_search()
        print(f"    âœ“ RRF k: {search.rrf_k}")
        print(f"    âœ“ Vector weight: {search.vector_weight}")
        
        # Hybrid ê²€ìƒ‰ (BM25ë§Œ í…ŒìŠ¤íŠ¸ - ì‹¤ì œ ì„ë² ë”© ì—†ì´)
        query = "íŠ¸ëŸ¼í”„ ê´€ì„¸ ì •ì±…"
        
        response = await search.search(
            query=query,
            n_results=3,
            where={"keyword": test_keyword},
            mode=SearchMode.BM25_ONLY,  # BM25ë§Œ í…ŒìŠ¤íŠ¸ (ì„ë² ë”© ì„œë¹„ìŠ¤ ì—†ì´)
        )
        
        print(f"    Query: '{query}'")
        print(f"    Mode: BM25_ONLY")
        print(f"    Results ({len(response.results)}):")
        for r in response.results:
            print(f"      [{r.final_rank}] score={r.hybrid_score:.4f}: {r.document[:40]}...")
        
        assert len(response.results) > 0, "Search returned no results"
        
        print_subheader("3.3 Search Metrics")
        
        metrics = response.metrics
        print(f"    âœ“ Total results: {metrics.total_results}")
        print(f"    âœ“ BM25 latency: {metrics.bm25_latency_ms:.1f}ms")
        print(f"    âœ“ Total latency: {metrics.total_latency_ms:.1f}ms")
        
        print_subheader("3.4 RRF Algorithm Test")
        
        # RRF ì•Œê³ ë¦¬ì¦˜ ì§ì ‘ í…ŒìŠ¤íŠ¸
        bm25_ranks = {"doc1": 1, "doc2": 3, "doc3": 5}
        vector_ranks = {"doc1": 2, "doc2": 1, "doc4": 4}
        
        fused = search._reciprocal_rank_fusion(bm25_ranks, vector_ranks)
        
        print("    BM25 ranks:", bm25_ranks)
        print("    Vector ranks:", vector_ranks)
        print("    RRF fused results:")
        for doc_id, score in fused[:5]:
            print(f"      {doc_id}: {score:.6f}")
        
        # doc1ê³¼ doc2ê°€ ì–‘ìª½ì— ìˆìœ¼ë¯€ë¡œ ìƒìœ„ì— ìˆì–´ì•¼ í•¨
        top_docs = [doc_id for doc_id, _ in fused[:2]]
        assert "doc1" in top_docs or "doc2" in top_docs, "RRF should rank overlapping docs higher"
        
        print_subheader("3.5 Metrics Summary")
        
        summary = search.get_metrics_summary()
        print(f"    âœ“ Total queries: {summary.get('count', 0)}")
        print(f"    âœ“ Avg latency: {summary.get('avg_total_latency_ms', 0):.1f}ms")
        
        print_subheader("3.6 Cleanup")
        
        vector_store.delete_by_keyword(test_keyword)
        bm25_index.clear()
        search.clear_metrics()
        print("    âœ“ Test data cleaned up")
        
        print("\nâœ… Hybrid Search tests passed!")
        return True
        
    except Exception as e:
        print(f"\nâŒ Hybrid Search test failed: {e}")
        import traceback
        traceback.print_exc()
        return False


async def test_performance_benchmark() -> bool:
    """ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬"""
    print_header("4. Performance Benchmark")
    
    try:
        from trendops.search.bm25_index import get_bm25_index, reset_bm25_index
        import random
        
        reset_bm25_index()
        index = get_bm25_index()
        
        print_subheader("4.1 BM25 Indexing Performance")
        
        # ëŒ€ëŸ‰ ë¬¸ì„œ ìƒì„±
        num_docs = 1000
        keywords = ["íŠ¸ëŸ¼í”„", "ê´€ì„¸", "ì‚¼ì„±ì „ì", "ë¹„íŠ¸ì½”ì¸", "AI", "ë°˜ë„ì²´"]
        
        docs = []
        for i in range(num_docs):
            keyword = random.choice(keywords)
            doc = f"{keyword} ê´€ë ¨ ë‰´ìŠ¤ {i}. ì´ê²ƒì€ í…ŒìŠ¤íŠ¸ ë¬¸ì„œì…ë‹ˆë‹¤. " * 3
            docs.append((f"bench_doc_{i}", doc, {"keyword": "__bench__"}))
        
        # ì¸ë±ì‹± ì‹œê°„ ì¸¡ì •
        start = time.time()
        index.add_documents(
            doc_ids=[d[0] for d in docs],
            documents=[d[1] for d in docs],
            metadatas=[d[2] for d in docs],
        )
        index_time = time.time() - start
        
        print(f"    âœ“ Indexed {num_docs} documents in {index_time:.2f}s")
        print(f"    âœ“ Rate: {num_docs / index_time:.0f} docs/sec")
        
        print_subheader("4.2 BM25 Search Performance")
        
        # ê²€ìƒ‰ ì‹œê°„ ì¸¡ì •
        queries = ["íŠ¸ëŸ¼í”„ ê´€ì„¸", "ì‚¼ì„±ì „ì ì£¼ê°€", "ë¹„íŠ¸ì½”ì¸ ê°€ê²©", "AI ë°˜ë„ì²´"]
        num_searches = 100
        
        start = time.time()
        for _ in range(num_searches):
            query = random.choice(queries)
            index.search(query, top_k=10)
        search_time = time.time() - start
        
        avg_search_ms = (search_time / num_searches) * 1000
        
        print(f"    âœ“ {num_searches} searches in {search_time:.2f}s")
        print(f"    âœ“ Avg search time: {avg_search_ms:.2f}ms")
        
        print_subheader("4.3 Index Stats")
        
        stats = index.get_stats()
        print(f"    âœ“ Documents: {stats.total_documents}")
        print(f"    âœ“ Vocabulary: {stats.vocabulary_size}")
        print(f"    âœ“ Avg doc length: {stats.avg_doc_length:.1f} tokens")
        
        # ì •ë¦¬
        index.clear()
        
        print("\nâœ… Performance benchmark completed!")
        return True
        
    except Exception as e:
        print(f"\nâŒ Performance benchmark failed: {e}")
        import traceback
        traceback.print_exc()
        return False


async def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("\n" + "â–ˆ" * 70)
    print("â–ˆ  Week 3 Day 5: Hybrid Search Integration Test")
    print("â–ˆ" * 70)
    
    results = {
        "VectorStore": await test_vector_store(),
        "BM25Index": await test_bm25_index(),
        "HybridSearch": await test_hybrid_search(),
        "Benchmark": await test_performance_benchmark(),
    }
    
    # ê²°ê³¼ ìš”ì•½
    print("\n" + "=" * 70)
    print("  TEST SUMMARY")
    print("=" * 70)
    
    passed = 0
    failed = 0
    
    for test_name, success in results.items():
        status = "âœ… PASS" if success else "âŒ FAIL"
        print(f"    {test_name}: {status}")
        if success:
            passed += 1
        else:
            failed += 1
    
    print("-" * 70)
    print(f"    Total: {passed} passed, {failed} failed")
    print("=" * 70)
    
    if failed == 0:
        print("\nğŸ‰ All tests passed! Hybrid Search is ready for production.")
    else:
        print("\nâš ï¸  Some tests failed. Please check the errors above.")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())