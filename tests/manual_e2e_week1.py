# tests/manual_e2e_week1.py
"""
TrendOps Week 1 E2E Integration Test
"""
import asyncio
import sys
from datetime import datetime
from pathlib import Path

sys.path.insert(0, str(Path(__file__).parent.parent / "src"))

from trendops.collector.collector_rss_google import GoogleNewsRSSCollector
from trendops.queue.queue_redis import RedisQueue
from trendops.trigger.trigger_google import GoogleTrendTrigger
from trendops.utils.logger import get_logger

logger = get_logger(__name__)


class C:
    H = "\033[95m"
    B = "\033[94m"
    C = "\033[96m"
    G = "\033[92m"
    Y = "\033[93m"
    R = "\033[91m"
    BOLD = "\033[1m"
    E = "\033[0m"


def header(t: str) -> None:
    print(f"\n{C.BOLD}{C.H}{'='*60}\n  {t}\n{'='*60}{C.E}")


def step(n: int, t: str) -> None:
    print(f"\n{C.BOLD}{C.C}[Step {n}/4]{C.E} {t}")


def ok(t: str) -> None:
    print(f"{C.G}âœ… {t}{C.E}")


def err(t: str) -> None:
    print(f"{C.R}âŒ {t}{C.E}")


def info(k: str, v: str) -> None:
    print(f"   {C.Y}{k}:{C.E} {v}")


async def run_e2e_test() -> bool:
    header("TrendOps Week 1 - E2E Integration Test")
    print(f"   ì‹œì‘: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

    q = RedisQueue()
    collector: GoogleNewsRSSCollector | None = None

    try:
        # Step 1
        step(1, "Google Trends í‚¤ì›Œë“œ ê°ì§€ â†’ Redis Queue")
        await q.connect()
        ok("Redis ì—°ê²° ì„±ê³µ")

        trigger = GoogleTrendTrigger(redis_queue=q)
        res = await trigger.run(min_score=0.0, max_keywords=1)

        if res["status"] != "success" or res["pushed"] == 0:
            err("íŠ¸ë Œë“œ í‚¤ì›Œë“œ ì‹¤íŒ¨")
            from trendops.queue.queue_models import TrendJob, TrendKeyword, TrendSource
            dummy = TrendJob(keyword_info=TrendKeyword(
                keyword="AI ë°˜ë„ì²´",
                source=TrendSource.GOOGLE,
                trend_score=8.0,
            ))
            await q.push_job(dummy)
            ok("Fallback í‚¤ì›Œë“œ 'AI ë°˜ë„ì²´' ì¶”ê°€")
        else:
            ok(f"í‚¤ì›Œë“œ ê°ì§€: {res.get('keywords', [])}")
            info("ê°ì§€", str(res["fetched"]))
            info("í ì¶”ê°€", str(res["pushed"]))

        stats = await q.get_queue_stats()
        info("Queue", f"pending={stats['pending']}, processing={stats['processing']}")

        # Step 2
        step(2, "Redis Queueì—ì„œ Job Pop")
        job = await q.pop_job(timeout=5)

        if job is None:
            err("Job Pop ì‹¤íŒ¨")
            return False

        ok("Job Pop ì„±ê³µ")
        info("Job ID", str(job.job_id))
        info("í‚¤ì›Œë“œ", job.keyword_info.keyword)
        info("ì ìˆ˜", str(job.keyword_info.trend_score))

        await q.mark_processing(job.job_id)
        ok("Job â†’ processing")

        # Step 3
        step(3, f"Google News RSS ìˆ˜ì§‘: '{job.keyword_info.keyword}'")
        
        # Context manager ì‚¬ìš©í•˜ì—¬ ì„¸ì…˜ ìë™ ì •ë¦¬
        async with GoogleNewsRSSCollector() as collector:
            result = await collector.fetch(keyword=job.keyword_info.keyword, max_results=5)

            if result.count == 0:
                err("ë‰´ìŠ¤ ìˆ˜ì§‘ ì‹¤íŒ¨")
                await q.mark_failed(job.job_id, "No articles")
                return False

            ok(f"ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {result.count}ê°œ")
            info("ìˆ˜ì§‘ ì‹œê°„", result.collected_at.strftime("%Y-%m-%d %H:%M:%S"))

        await q.mark_completed(job.job_id)
        ok("Job â†’ completed")

        # Step 4
        step(4, "ê²°ê³¼ ì¶œë ¥")
        print(f"\n{'â”€'*60}")
        print(f"{C.BOLD}ğŸ“° ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ({result.count}ê±´){C.E}")
        print(f"{'â”€'*60}")

        for i, a in enumerate(result.articles, 1):
            pub = a.published.strftime("%Y-%m-%d %H:%M") if a.published else "N/A"
            print(f"\n   {C.BOLD}{i}. {a.title}{C.E}")
            link_str = str(a.link)
            print(f"      ğŸ”— {link_str[:70]}...")
            print(f"      ğŸ“… {pub}")

        print(f"\n{'â”€'*60}")

        final = await q.get_queue_stats()
        print(f"\n{C.BOLD}ğŸ“Š ìµœì¢… Queue ìƒíƒœ{C.E}")
        info("Pending", str(final["pending"]))
        info("Processing", str(final["processing"]))
        info("Completed", str(final["completed"]))

        return True

    except Exception as e:
        err(f"í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        logger.exception("E2E test failed")
        return False

    finally:
        await q.disconnect()


async def main() -> None:
    print(f"\n{C.BOLD}{C.B}")
    print(r"""
  _____                    _  ___
 |_   _| __ ___ _ __   __| |/ _ \ _ __  ___
   | || '__/ _ \ '_ \ / _` | | | | '_ \/ __|
   | || | |  __/ | | | (_| | |_| | |_) \__ \
   |_||_|  \___|_| |_|\__,_|\___/| .__/|___/
                                 |_|
    Week 1: Data Ingestion Foundation
    """)
    print(C.E)

    success = await run_e2e_test()

    header("í…ŒìŠ¤íŠ¸ ê²°ê³¼")

    if success:
        print(f"""
   {C.G}{C.BOLD}
   âœ… Week 1 E2E í…ŒìŠ¤íŠ¸ í†µê³¼!

   ê²€ì¦ëœ ëª¨ë“ˆ:
   â”œâ”€â”€ trigger/trigger_google.py
   â”œâ”€â”€ queue/queue_redis.py
   â”œâ”€â”€ queue/queue_models.py
   â”œâ”€â”€ collector/collector_rss_google.py
   â”œâ”€â”€ config/settings.py
   â””â”€â”€ utils/logger.py

   ë‹¤ìŒ: Week 2 - LLM ì—°ë™
   {C.E}""")
    else:
        print(f"""
   {C.R}{C.BOLD}
   âŒ Week 1 E2E í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨

   í™•ì¸:
   1. Redis ì‹¤í–‰ í™•ì¸ (docker-compose up -d)
   2. .env ì„¤ì • í™•ì¸
   3. ë„¤íŠ¸ì›Œí¬ ìƒíƒœ í™•ì¸
   {C.E}""")
        sys.exit(1)


if __name__ == "__main__":
    asyncio.run(main())