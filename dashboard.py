import streamlit as st
import asyncio
import pandas as pd
import plotly.express as px
import time
import feedparser
import requests
import random
from datetime import datetime

# TrendOps ëª¨ë“ˆ ì„í¬íŠ¸
from trendops.collector.collector_rss import RSSCollector
from trendops.analyst.structured_analyzer import StructuredAnalyzer
from trendops.store.vector_store import get_vector_store

#streamlit run dashboard.py

# -----------------------------------------------------------------------------
# í˜ì´ì§€ ì„¤ì •
# -----------------------------------------------------------------------------
st.set_page_config(
    page_title="TrendOps AI Dashboard",
    page_icon="ğŸ”¥",
    layout="wide",
    initial_sidebar_state="expanded"
)

st.markdown("""
<style>
    .metric-card {
        background-color: #1E1E1E;
        padding: 15px;
        border-radius: 10px;
        border: 1px solid #333;
        margin-bottom: 10px;
    }
</style>
""", unsafe_allow_html=True)

# -----------------------------------------------------------------------------
# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
# -----------------------------------------------------------------------------
if 'analysis_result' not in st.session_state:
    st.session_state.analysis_result = None
if 'articles_data' not in st.session_state:
    st.session_state.articles_data = None
if 'image_result' not in st.session_state:
    st.session_state.image_result = None
if 'current_keyword' not in st.session_state:
    st.session_state.current_keyword = ""

# -----------------------------------------------------------------------------
# Helper Functions
# -----------------------------------------------------------------------------
def run_async(coro):
    """ë¹„ë™ê¸° ì‹¤í–‰ ë˜í¼"""
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    return loop.run_until_complete(coro)

@st.cache_data(ttl=600)
def get_realtime_trends(geo="KR"):
    """
    [í•µì‹¬ ìˆ˜ì •] trigger_google.pyì˜ ì„±ê³µ URL ì ìš©
    URL: https://trends.google.com/trending/rss?geo=KR
    """
    try:
        current_time = datetime.now().strftime("%H:%M:%S")
        
        # âœ… trigger_google.pyì—ì„œ í™•ì¸ëœ 'ì§„ì§œ' ì‘ë™í•˜ëŠ” ì£¼ì†Œ
        url = f"https://trends.google.com/trending/rss?geo={geo}"
        
        # âœ… trigger_google.pyì˜ í—¤ë” ì„¤ì • ê·¸ëŒ€ë¡œ ì ìš©
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            "Accept": "application/rss+xml, application/xml, text/xml",
            "Accept-Language": "ko-KR,ko;q=0.9,en-US;q=0.8,en;q=0.7",
        }
        
        # 1. Requestsë¡œ ë°ì´í„° ìš”ì²­
        response = requests.get(url, headers=headers, timeout=10)
        
        if response.status_code != 200:
            # 200 OKê°€ ì•„ë‹ˆë©´ ì—ëŸ¬ ë©”ì‹œì§€ ë°˜í™˜
            return [], f"HTTP Error: {response.status_code}"

        # 2. íŒŒì‹±
        feed = feedparser.parse(response.content)
        
        if not feed.entries:
            return [], "Empty Feed (ë°ì´í„° ì—†ìŒ)"
            
        trends = [entry.title for entry in feed.entries]
        return trends, current_time
        
    except Exception as e:
        return [], f"Error: {str(e)}"

# -----------------------------------------------------------------------------
# ì‚¬ì´ë“œë°”
# -----------------------------------------------------------------------------
with st.sidebar:
    st.title("ğŸ”¥ TrendOps Control")
    st.markdown("---")
    
    st.subheader("ğŸ“ˆ Real-time Trends")
    
    # ìƒˆë¡œê³ ì¹¨ ë²„íŠ¼
    col_ref, col_time = st.columns([1, 1])
    with col_ref:
        if st.button("ğŸ”„ ìƒˆë¡œê³ ì¹¨", use_container_width=True):
            get_realtime_trends.clear()
            st.rerun()
            
    trends, status_msg = get_realtime_trends()
    
    with col_time:
        if "Error" in status_msg or "HTTP" in status_msg:
             st.error("Error")
        else:
             st.caption(f"Update:\n{status_msg}")

    st.markdown("ğŸ‘‡ **ë¶„ì„í•  í‚¤ì›Œë“œ í´ë¦­**")
    
    # ì—ëŸ¬ ë©”ì‹œì§€ê°€ ìˆìœ¼ë©´ ìì„¸íˆ í‘œì‹œ
    if "Error" in status_msg:
        st.error(status_msg)
    elif not trends:
        st.warning("ë°ì´í„° ë¡œë”© ì¤‘...")
    
    # íŠ¸ë Œë“œ ëª©ë¡ ì¶œë ¥
    for keyword in trends:
        if st.button(f"ğŸ”¥ {keyword}", key=f"trend_{keyword}", use_container_width=True):
            st.session_state.current_keyword = keyword
            st.session_state.analysis_result = None
            st.session_state.image_result = None
            st.rerun()

    st.markdown("---")
    st.subheader("âš™ï¸ Settings")
    
    model_name = st.selectbox("LLM Model", ["exaone3.5"], index=0)
    max_articles = st.slider("Max Articles", 5, 50, 20)
    enable_image = st.checkbox("Card News", value=True)

# -----------------------------------------------------------------------------
# ë©”ì¸ í™”ë©´
# -----------------------------------------------------------------------------
st.title("ğŸ“Š TrendOps: ì§€ëŠ¥í˜• íŠ¸ë Œë“œ ë¶„ì„")

tab1, tab2, tab3 = st.tabs(["ğŸš€ ë¶„ì„ ì‹¤í–‰", "ğŸ—„ï¸ DB í™•ì¸", "ğŸ› ï¸ ì‹œìŠ¤í…œ ìƒíƒœ"])

# TAB 1: ë¶„ì„
with tab1:
    col_input, col_btn = st.columns([4, 1])
    
    with col_input:
        keyword = st.text_input(
            "í‚¤ì›Œë“œ ì…ë ¥", 
            value=st.session_state.current_keyword,
            placeholder="ì‚¬ì´ë“œë°”ì—ì„œ íŠ¸ë Œë“œë¥¼ ì„ íƒí•˜ê±°ë‚˜ ì§ì ‘ ì…ë ¥í•˜ì„¸ìš”",
            label_visibility="collapsed"
        )
        
    with col_btn:
        analyze_btn = st.button("ğŸš€ ë¶„ì„ ì‹œì‘", use_container_width=True, type="primary")

    if analyze_btn and keyword:
        st.session_state.current_keyword = keyword
        status_container = st.container()
        
        with status_container:
            with st.status("ğŸ•µï¸ ì—ì´ì „íŠ¸ê°€ ì‘ì—… ì¤‘ì…ë‹ˆë‹¤...", expanded=True) as status:
                try:
                    # 1. ìˆ˜ì§‘
                    st.write(f"ğŸ” Google News ìˆ˜ì§‘ ì¤‘: '{keyword}'")
                    async def fetch():
                        async with RSSCollector(max_results=max_articles) as c:
                            return await c.fetch(keyword)
                    
                    documents = run_async(fetch())
                    
                    if not documents:
                        status.update(label="âŒ ê¸°ì‚¬ ì—†ìŒ", state="error")
                        st.error("ê´€ë ¨ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                        st.stop()
                    
                    st.write(f"âœ… {len(documents)}ê±´ ìˆ˜ì§‘ ì™„ë£Œ")
                    
                    articles_list = [
                        {
                            "title": d.title, 
                            "summary": d.summary, 
                            "source": d.source, 
                            "published": str(d.published),
                            # [ì¤‘ìš”] ì¤‘ë³µ ì œê±°ìš© keyword ì¶”ê°€
                            "keyword": keyword 
                        }
                        for d in documents
                    ]
                    st.session_state.articles_data = articles_list

                    # 2. ë¶„ì„
                    st.write(f"ğŸ§  {model_name} ë¶„ì„ ì¤‘...")
                    async def analyze():
                        async with StructuredAnalyzer(model_name=model_name) as a:
                            return await a.analyze(keyword, articles_list)
                    
                    an_res = run_async(analyze())
                    st.session_state.analysis_result = an_res
                    st.write("âœ… ë¶„ì„ ì™„ë£Œ")

                    status.update(label="ğŸ‰ ì‘ì—… ì™„ë£Œ!", state="complete")
                    
                except Exception as e:
                    status.update(label="âš ï¸ ì—ëŸ¬ ë°œìƒ", state="error")
                    st.error(f"Error: {e}")
                    st.stop()

    # ê²°ê³¼ í‘œì‹œ
    if st.session_state.analysis_result:
        res = st.session_state.analysis_result.analysis
        
        st.divider()
        st.header(f"ğŸ”¥ ë¶„ì„ ë¦¬í¬íŠ¸: {st.session_state.current_keyword}")
        
        c1, c2, c3 = st.columns([2, 1, 1])
        
        with c1:
            st.markdown("### ğŸ“Œ í•µì‹¬ ì›ì¸")
            st.info(res.main_cause)
            st.markdown("### ğŸ“ 3ì¤„ ìš”ì•½")
            st.write(res.summary)

        with c2:
            st.markdown("### ğŸ“Š ê°ì„± ë¶„ì„")
            sent_data = res.sentiment_ratio.model_dump()
            fig = px.pie(
                values=list(sent_data.values()), 
                names=list(sent_data.keys()),
                color=list(sent_data.keys()),
                color_discrete_map={'positive':'#4ade80', 'negative':'#f87171', 'neutral':'#9ca3af'},
                hole=0.6
            )
            fig.update_layout(showlegend=False, margin=dict(t=0, b=0, l=0, r=0), height=200)
            st.plotly_chart(fig, use_container_width=True)


        c3, c4 = st.columns(2)
        with c3:
            st.markdown("### ğŸ’¬ ì£¼ìš” ë°˜ì‘")
            for op in res.key_opinions:
                st.success(f"â€¢ {op}")
        
        with c4:
            st.markdown("### ğŸ“° ì›ë³¸ ë‰´ìŠ¤")
            if st.session_state.articles_data:
                df = pd.DataFrame(st.session_state.articles_data)
                st.dataframe(df[['title', 'source']], height=200, hide_index=True)

# TAB 2: DB
with tab2:
    st.subheader("ğŸ—„ï¸ ë²¡í„° DB ìƒíƒœ")
    try:
        store = get_vector_store()
        stats = store.get_stats()
        st.metric("ì´ ë¬¸ì„œ ìˆ˜", stats.count)
        st.caption(f"Path: {store.persist_path}")
    except:
        st.warning("DB ì—†ìŒ")

# TAB 3: ì‹œìŠ¤í…œ
with tab3:
    st.subheader("ğŸ–¥ï¸ ì‹œìŠ¤í…œ ìƒíƒœ")
    try:
        import requests
        res = requests.get("http://localhost:11434/api/tags")
        if res.status_code == 200:
            st.success("âœ… Ollama ì—°ê²°ë¨")
            st.json([m['name'] for m in res.json()['models']])
    except:
        st.error("âŒ Ollama ì—°ê²° ì‹¤íŒ¨")